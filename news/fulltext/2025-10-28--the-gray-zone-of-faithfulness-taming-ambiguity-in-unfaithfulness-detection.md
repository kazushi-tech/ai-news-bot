---
title: "The Gray Zone of Faithfulness: Taming Ambiguity in Unfaithfulness Detection"
date: 2025-10-28
url: https://arxiv.org/abs/2510.21118
domain: arxiv.org
lang: en
tags: ["Paper"]
---
# The Gray Zone of Faithfulness: Taming Ambiguity in Unfaithfulness Detection

## ðŸ”— å¼•ç”¨å…ƒ
- **URL**: https://arxiv.org/abs/2510.21118
- **ã‚µã‚¤ãƒˆ**: arXiv.org
- **è‘—è€…**: [Submitted on 24 Oct 2025 (v1), last revised 27 Oct 2025 (this version, v2)]
- **è¨€èªž**: English
## ðŸ§­ æ¦‚è¦
View PDF
    HTML (experimental)
            Abstract:Ensuring that Large Language Models (LLMs) generate summaries faithful to a given source document is essential for real-world applications. While prior research has explored LLM faithfulness, existing benchmarks suffer from annotation ambiguity, primarily due to the ill-defined boundary of permissible external knowledge in generated outputs. For instance, common sense is often incorporated into responses and labeled as "faithful", yet the acceptable extent of such knowledge remains unspecified, leading to inconsistent annotations. To address this issue, we propose a novel faithfulness annotation framework, which introduces an intermediate category, Out-Dependent, to classify cases where external knowledge is required for verification.

## ðŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
[View PDF](https://arxiv.org/pdf/2510.21118) [HTML (experimental)](https://arxiv.org/html/2510.21118v2)

> Abstract:Ensuring that Large Language Models (LLMs) generate summaries faithful to a given source document is essential for real-world applications. While prior research has explored LLM faithfulness, existing benchmarks suffer from annotation ambiguity, primarily due to the ill-defined boundary of permissible external knowledge in generated outputs. For instance, common sense is often incorporated into responses and labeled as "faithful", yet the acceptable extent of such knowledge remains unspecified, leading to inconsistent annotations. To address this issue, we propose a novel faithfulness annotation framework, which introduces an intermediate category, Out-Dependent, to classify cases where external knowledge is required for verification. Using this framework, we construct VeriGray (Verification with the Gray Zone) -- a new unfaithfulness detection benchmark in summarization. Statistics reveal that even SOTA LLMs, such as GPT-5, exhibit hallucinations ($\\sim 6\\%$ of sentences) in summarization tasks. Moreover, a substantial proportion ($\\sim 8\\%$ on average of models) of generated sentences fall into the Out-Dependent category, underscoring the importance of resolving annotation ambiguity in unfaithfulness detection benchmarks. Experiments demonstrate that our benchmark poses significant challenges to multiple baseline methods, indicating considerable room for future improvement.

Submission history
------------------

From: Qiang Ding \[[view email](https://arxiv.org/show-email/2e9d2449/2510.21118)\]  
**[\[v1\]](https://arxiv.org/abs/2510.21118v1)** Fri, 24 Oct 2025 03:13:51 UTC (169 KB)  
**\[v2\]** Mon, 27 Oct 2025 02:50:12 UTC (170 KB)
