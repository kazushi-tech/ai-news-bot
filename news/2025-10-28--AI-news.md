# 2025-10-28 - AIニュース

| タイトル                                                                                                                                                             |                                                     記事                                                    |                    引用元                   | 要約                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------: | :--------------------------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [A Multi-Component AI Framework for Computational Psychology: From Robust Predictive Modeling to Deployed Generative Dialogue](https://arxiv.org/abs/2510.21720) | [記事ページへ](2025-10-28--a-multi-component-ai-framework-for-computational-psychology-from-robust-predicti.md) | [引用元へ](https://arxiv.org/abs/2510.21720) | Data provided by: ### Bookmark Bibliographic Tools # Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media # Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv (What is alphaXiv?) Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Huggingface Toggle Hugging Face (What is Huggingface?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos # Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers # Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Core recommender toggle CORE Recommender (What is CORE?) Author Venue Institution Topic About arXivLabs # arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Subjects: Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG) Cite as: arXiv:2510.21720 [cs.AI] &nbsp; (or arXiv:2510.21720v1 [cs.AI] for this version) &nbsp; https://doi.org/10.48550/arXiv.2510.21720 Focus to learn more arXiv-issued DOI via DataCite ## Submission history From: Anant Pareek [view email] [v1] Tue, 16 Sep 2025 13:33:40 UTC (15 KB) Full-text links: ## Access Paper: View a PDF of the paper titled A Multi-Component AI Framework for Computational Psychology: From Robust Predictive Modeling to Deployed Generative Dialogue, by Anant PareekView PDFHTML (experimental)TeX Source view license Current browse context: cs.AI &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2025-10 Change to browse by: cs cs.HC cs.LG ### References &amp; Citations NASA ADSGoogle Scholar Semantic Scholar export BibTeX citation Loading... Donate &gt; cs &gt; arXiv:2510.21720 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu ## quick links Login Help Pages About --> # Computer Science > Artificial Intelligence arXiv:2510.21720 (cs) [Submitted on 16 Sep 2025] # Title:A Multi-Component AI Framework for Computational Psychology: From Robust Predictive Modeling to Deployed Generative Dialogue Authors:Anant Pareek View a PDF of the paper titled A Multi-Component AI Framework for Computational Psychology: From Robust Predictive Modeling to Deployed Generative Dialogue, by Anant Pareek View PDF HTML (experimental) Abstract:The confluence of Artificial Intelligence and Computational Psychology presents an opportunity to model, understand, and interact with complex human psychological states through computational means.                                                                        |
| [PREFINE: Personalized Story Generation via Simulated User Critics and User-Specific Rubric Generation](https://arxiv.org/abs/2510.21721)                        | [記事ページへ](2025-10-28--prefine-personalized-story-generation-via-simulated-user-critics-and-user-specif.md) | [引用元へ](https://arxiv.org/abs/2510.21721) | Data provided by: ### Bookmark Bibliographic Tools # Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media # Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv (What is alphaXiv?) Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Huggingface Toggle Hugging Face (What is Huggingface?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos # Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers # Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Core recommender toggle CORE Recommender (What is CORE?) Author Venue Institution Topic About arXivLabs # arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Donate &gt; cs &gt; arXiv:2510.21721 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu ## quick links Login Help Pages About --> # Computer Science > Artificial Intelligence arXiv:2510.21721 (cs) [Submitted on 16 Sep 2025] # Title:PREFINE: Personalized Story Generation via Simulated User Critics and User-Specific Rubric Generation Authors:Kentaro Ueda, Takehiro Takayanagi View a PDF of the paper titled PREFINE: Personalized Story Generation via Simulated User Critics and User-Specific Rubric Generation, by Kentaro Ueda and 1 other authors View PDF HTML (experimental) Abstract:While recent advances in Large Language Models (LLMs) have improved the quality of creative text generation, significant challenges remain in producing personalized stories that reflect individual user preferences. Subjects: Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC) Cite as: arXiv:2510.21721 [cs.AI] &nbsp; (or arXiv:2510.21721v1 [cs.AI] for this version) &nbsp; https://doi.org/10.48550/arXiv.2510.21721 Focus to learn more arXiv-issued DOI via DataCite ## Submission history From: Kentaro Ueda [view email] [v1] Tue, 16 Sep 2025 16:39:40 UTC (2,982 KB) Full-text links: ## Access Paper: View a PDF of the paper titled PREFINE: Personalized Story Generation via Simulated User Critics and User-Specific Rubric Generation, by Kentaro Ueda and 1 other authorsView PDFHTML (experimental)TeX Source view license Current browse context: cs.AI &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2025-10 Change to browse by: cs cs.HC ### References &amp; Citations NASA ADSGoogle Scholar Semantic Scholar export BibTeX citation Loading...                                                                                             |
| [SIGN: Schema-Induced Games for Naming](https://arxiv.org/abs/2510.21855)                                                                                        |                       [記事ページへ](2025-10-28--sign-schema-induced-games-for-naming.md)                       | [引用元へ](https://arxiv.org/abs/2510.21855) | Data provided by: ### Bookmark Bibliographic Tools # Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media # Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv (What is alphaXiv?) Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Huggingface Toggle Hugging Face (What is Huggingface?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos # Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers # Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Core recommender toggle CORE Recommender (What is CORE?) Author Venue Institution Topic About arXivLabs # arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Code available ar this https URL Subjects: Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multiagent Systems (cs.MA) ACM&nbsp;classes: I.2; I.2.7; I.2.11 Cite as: arXiv:2510.21855 [cs.AI] &nbsp; (or arXiv:2510.21855v1 [cs.AI] for this version) &nbsp; https://doi.org/10.48550/arXiv.2510.21855 Focus to learn more arXiv-issued DOI via DataCite (pending registration) ## Submission history From: Ryan Zhang [view email] [v1] Wed, 22 Oct 2025 23:12:06 UTC (1,354 KB) Full-text links: ## Access Paper: View a PDF of the paper titled SIGN: Schema-Induced Games for Naming, by Ryan Zhang and 1 other authorsView PDFHTML (experimental)TeX Source view license Current browse context: cs.AI &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2025-10 Change to browse by: cs cs.CL cs.LG cs.MA ### References &amp; Citations NASA ADSGoogle Scholar Semantic Scholar export BibTeX citation Loading... Donate &gt; cs &gt; arXiv:2510.21855 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu ## quick links Login Help Pages About --> # Computer Science > Artificial Intelligence arXiv:2510.21855 (cs) [Submitted on 22 Oct 2025] # Title:SIGN: Schema-Induced Games for Naming Authors:Ryan Zhang, Herbert Woisetscläger View a PDF of the paper titled SIGN: Schema-Induced Games for Naming, by Ryan Zhang and 1 other authors View PDF HTML (experimental) Abstract:Real-world AI systems are tackling increasingly complex problems, often through interactions among large language model (LLM) agents.                                                                                                                                                                                                                       |
| [Capability Ceilings in Autoregressive Language Models: Empirical Evidence from Knowledge-Intensive Tasks](https://arxiv.org/abs/2510.21866)                     | [記事ページへ](2025-10-28--capability-ceilings-in-autoregressive-language-models-empirical-evidence-from-kn.md) | [引用元へ](https://arxiv.org/abs/2510.21866) | Data provided by: ### Bookmark Bibliographic Tools # Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media # Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv (What is alphaXiv?) Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Huggingface Toggle Hugging Face (What is Huggingface?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos # Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers # Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Core recommender toggle CORE Recommender (What is CORE?) Author Venue Institution Topic About arXivLabs # arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Donate &gt; cs &gt; arXiv:2510.21866 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu ## quick links Login Help Pages About --> # Computer Science > Artificial Intelligence arXiv:2510.21866 (cs) [Submitted on 23 Oct 2025] # Title:Capability Ceilings in Autoregressive Language Models: Empirical Evidence from Knowledge-Intensive Tasks Authors:Javier Marín View a PDF of the paper titled Capability Ceilings in Autoregressive Language Models: Empirical Evidence from Knowledge-Intensive Tasks, by Javier Mar\&#39;in View PDF HTML (experimental) Abstract:We document empirical capability ceilings in decoder-only autoregressive language models across knowledge-intensive tasks. Current model architectures are considerably more complex than those presented here Subjects: Artificial Intelligence (cs.AI) Cite as: arXiv:2510.21866 [cs.AI] &nbsp; (or arXiv:2510.21866v1 [cs.AI] for this version) &nbsp; https://doi.org/10.48550/arXiv.2510.21866 Focus to learn more arXiv-issued DOI via DataCite (pending registration) ## Submission history From: Javier Marín [view email] [v1] Thu, 23 Oct 2025 11:09:31 UTC (813 KB) Full-text links: ## Access Paper: View a PDF of the paper titled Capability Ceilings in Autoregressive Language Models: Empirical Evidence from Knowledge-Intensive Tasks, by Javier Mar\&#39;inView PDFHTML (experimental)TeX Source view license Current browse context: cs.AI &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2025-10 Change to browse by: cs ### References &amp; Citations NASA ADSGoogle Scholar Semantic Scholar export BibTeX citation Loading...                                                                                                                                                                  |
| [GeoThought: A Dataset for Enhancing Mathematical Geometry Reasoning in Vision-Language Models](https://arxiv.org/abs/2510.21881)                                | [記事ページへ](2025-10-28--geothought-a-dataset-for-enhancing-mathematical-geometry-reasoning-in-vision-lan.md) | [引用元へ](https://arxiv.org/abs/2510.21881) | Data provided by: ### Bookmark Bibliographic Tools # Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media # Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv (What is alphaXiv?) Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Huggingface Toggle Hugging Face (What is Huggingface?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos # Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers # Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Core recommender toggle CORE Recommender (What is CORE?) Author Venue Institution Topic About arXivLabs # arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Donate &gt; cs &gt; arXiv:2510.21881 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu ## quick links Login Help Pages About --> # Computer Science > Artificial Intelligence arXiv:2510.21881 (cs) [Submitted on 23 Oct 2025] # Title:GeoThought: A Dataset for Enhancing Mathematical Geometry Reasoning in Vision-Language Models Authors:Nannan Shi, Chuanyu Qin, Shipeng Song, Man Luo View a PDF of the paper titled GeoThought: A Dataset for Enhancing Mathematical Geometry Reasoning in Vision-Language Models, by Nannan Shi and 3 other authors View PDF HTML (experimental) Abstract:Large language models (LLMs) have demonstrated strong reasoning capabilities in text-based mathematical problem solving; however, when adapted to visual reasoning tasks, particularly geometric problem solving, their performance substantially declines because geometric problems present unique challenges. Subjects: Artificial Intelligence (cs.AI); Computation and Language (cs.CL) Cite as: arXiv:2510.21881 [cs.AI] &nbsp; (or arXiv:2510.21881v1 [cs.AI] for this version) &nbsp; https://doi.org/10.48550/arXiv.2510.21881 Focus to learn more arXiv-issued DOI via DataCite (pending registration) ## Submission history From: Nannan Shi [view email] [v1] Thu, 23 Oct 2025 16:43:54 UTC (192 KB) Full-text links: ## Access Paper: View a PDF of the paper titled GeoThought: A Dataset for Enhancing Mathematical Geometry Reasoning in Vision-Language Models, by Nannan Shi and 3 other authorsView PDFHTML (experimental)TeX Source view license Current browse context: cs.AI &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2025-10 Change to browse by: cs cs.CL ### References &amp; Citations NASA ADSGoogle Scholar Semantic Scholar export BibTeX citation Loading... |
