# 🗓 週間インデックス

**生成日**: 2025-10-28

## 2025-10-26

# AI News — 2025-10-26

- [Andrej Karpathy — AGI is still a decade away](./2025-10-26-andrej-karpathy--agi-is-still-a-decade-away-dc08e95a.md) — Dwarkesh Podcast

## 2025-10-27

---
title: "AI News — 2025-10-27"
date: 2025-10-27
tags: [ai-news, daily-index]
---

# AI News — 2025-10-27

| タイトル | 記事 | 引用元 | 要約 |
|---|---|---|---|
| Andrej Karpathy — AGI is still a decade away | [記事ページ](./2025-10-27-andrej-karpathy-agi-is-still-a-decade-away-dc08e95a.md) | [引用元](https://www.dwarkesh.com/p/andrej-karpathy) | [Labelbox](https://labelbox.com/dwarkesh) helps you get data that is more detailed, more accurate, and higher signal than you could get by default, no matter your domain or trainin |
| Andrej Karpathy — AGI is still a decade away | [記事ページ](./2025-10-27-andrej-karpathy-agi-is-still-a-decade-away-dc08e95a.md) | [引用元](https://www.dwarkesh.com/p/andrej-karpathy) | [Labelbox](https://labelbox.com/dwarkesh) helps you get data that is more detailed, more accurate, and higher signal than you could get by default, no matter your domain or trainin |
| Andrej Karpathy — AGI is still a decade away | [記事ページ](./2025-10-27-andrej-karpathy-agi-is-still-a-decade-away-dc08e95a.md) | [引用元](https://www.dwarkesh.com/p/andrej-karpathy) | [Labelbox](https://labelbox.com/dwarkesh) helps you get data that is more detailed, more accurate, and higher signal than you could get by default, no matter your domain or trainin |
| Andrej Karpathy — AGI is still a decade away | [記事ページ](./2025-10-27-andrej-karpathy-agi-is-still-a-decade-away-dc08e95a.md) | [引用元](https://www.dwarkesh.com/p/andrej-karpathy) | [Labelbox](https://labelbox.com/dwarkesh) helps you get data that is more detailed, more accurate, and higher signal than you could get by default, no matter your domain or trainin |
| Latest News from Google Research Blog - Google Research | [記事ページ](./2025-10-27-latest-news-from-google-research-blog-google-research-fc993854.md) | [引用元](https://ai.googleblog.com/) | [ / Climate & Sustainability · / Generative AI · / Machine Perception / [ |
| Andrej Karpathy — AGI is still a decade away | [記事ページ](./2025-10-27-andrej-karpathy-agi-is-still-a-decade-away-dc08e95a.md) | [引用元](https://www.dwarkesh.com/p/andrej-karpathy) | [Labelbox](https://labelbox.com/dwarkesh) helps you get data that is more detailed, more accurate, and higher signal than you could get by default, no matter your domain or trainin |
| Andrej Karpathy — AGI is still a decade away | [記事ページ](./2025-10-27-andrej-karpathy-agi-is-still-a-decade-away-dc08e95a.md) | [引用元](https://www.dwarkesh.com/p/andrej-karpathy) | [Labelbox](https://labelbox.com/dwarkesh) helps you get data that is more detailed, more accurate, and higher signal than you could get by default, no matter your domain or trainin |
| Andrej Karpathy — AGI is still a decade away | [記事ページ](./2025-10-27-andrej-karpathy-agi-is-still-a-decade-away-dc08e95a.md) | [引用元](https://www.dwarkesh.com/p/andrej-karpathy) | [Labelbox](https://labelbox.com/dwarkesh) helps you get data that is more detailed, more accurate, and higher signal than you could get by default, no matter your domain or trainin |
| Andrej Karpathy — AGI is still a decade away | [記事ページ](./2025-10-27-andrej-karpathy-agi-is-still-a-decade-away-dc08e95a.md) | [引用元](https://www.dwarkesh.com/p/andrej-karpathy) | [Labelbox](https://labelbox.com/dwarkesh) helps you get data that is more detailed, more accurate, and higher signal than you could get by default, no matter your domain or trainin |


## 2025-10-28

# AIニュース (2025-10-28)

| 時刻(JST) | タイトル | 出典 | 言語 | タグ |
|---|---|---|---|---|
| 10:37 | [Google DeepMind is bringing AI to the next generation of fusion energy](https://deepmind.google/discover/blog/bringing-ai-to-the-next-generation-of-fusion-energy/) | deepmind.google | en | Google,Research |

| 時刻(JST) | タイトル | 出典 | 言語 | タグ |
|---|---|---|---|---|
| 11:06 | [How a Gemma model helped discover a new potential cancer therapy pathway](https://blog.google/technology/ai/google-gemma-ai-cancer-therapy-discovery/) | blog.google | en |  |

| 時刻(JST) | タイトル | 出典 | 言語 | タグ |
|---|---|---|---|---|
| 12:33 | [Streaming datasets: 100x More Efficient](https://huggingface.co/blog/streaming-datasets) | huggingface.co | en | HuggingFace,OSS |
| 12:33 | [huggingface_hub v1.0: Five Years of Building the Foundation of Open Machine Learning](https://huggingface.co/blog/huggingface-hub-v1) | huggingface.co | en | HuggingFace,OSS |
| 12:33 | [Building the Open Agent Ecosystem Together: Introducing OpenEnv](https://huggingface.co/blog/openenv) | huggingface.co | en | HuggingFace,OSS |
| 12:33 | [Hugging Face and VirusTotal collaborate to strengthen AI security](https://huggingface.co/blog/virustotal) | huggingface.co | en | HuggingFace,OSS |
| 12:33 | [Sentence Transformers is joining Hugging Face!](https://huggingface.co/blog/sentence-transformers-joins-hf) | huggingface.co | en | HuggingFace,OSS |
| 12:33 | [LeRobot v0.4.0: Super Charging OSS Robotics Learning](https://huggingface.co/blog/lerobot-release-v040) | huggingface.co | en | HuggingFace,OSS |
| 12:33 | [Shoot First, Ask Questions Later? Building Rational Agents that Explore and Act Like People](https://arxiv.org/abs/2510.20886) | arxiv.org | en | Paper |
| 12:33 | [Code-enabled language models can outperform reasoning models on diverse tasks](https://arxiv.org/abs/2510.20909) | arxiv.org | en | Paper |
| 12:33 | [FicSim: A Dataset for Multi-Faceted Semantic Similarity in Long-Form Fiction](https://arxiv.org/abs/2510.20926) | arxiv.org | en | Paper |
| 12:33 | [Do LLMs Truly Understand When a Precedent Is Overruled?](https://arxiv.org/abs/2510.20941) | arxiv.org | en | Paper |
| 12:33 | [Irish-BLiMP: A Linguistic Benchmark for Evaluating Human and Language Model Performance in a Low-Resource Setting](https://arxiv.org/abs/2510.20957) | arxiv.org | en | Paper |
| 12:33 | [Can Confidence Estimates Decide When Chain-of-Thought Is Necessary for LLMs?](https://arxiv.org/abs/2510.21007) | arxiv.org | en | Paper |
| 12:33 | [Input Matters: Evaluating Input Structure's Impact on LLM Summaries of Sports Play-by-Play](https://arxiv.org/abs/2510.21034) | arxiv.org | en | Paper |
| 12:33 | [Reasoning's Razor: Reasoning Improves Accuracy but Can Hurt Recall at Critical Operating Points in Safety and Hallucination Detection](https://arxiv.org/abs/2510.21049) | arxiv.org | en | Paper |
| 12:33 | [Dynamic Retriever for In-Context Knowledge Editing via Policy Optimization](https://arxiv.org/abs/2510.21059) | arxiv.org | en | Paper |
| 12:33 | [Bridging Language Gaps with Adaptive RAG: Improving Indonesian Language Question Answering](https://arxiv.org/abs/2510.21068) | arxiv.org | en | Paper |
| 12:33 | [CDrugRed: A Chinese Drug Recommendation Dataset for Discharge Medications in Metabolic Diseases](https://arxiv.org/abs/2510.21084) | arxiv.org | en | Paper |
| 12:33 | [Self-Rewarding PPO: Aligning Large Language Models with Demonstrations Only](https://arxiv.org/abs/2510.21090) | arxiv.org | en | Paper |
| 12:33 | [The Gray Zone of Faithfulness: Taming Ambiguity in Unfaithfulness Detection](https://arxiv.org/abs/2510.21118) | arxiv.org | en | Paper |
| 12:33 | [Large Language Models Meet Text-Attributed Graphs: A Survey of Integration Frameworks and Applications](https://arxiv.org/abs/2510.21131) | arxiv.org | en | Paper |
